{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e06b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sweta Rana\\scoop\\apps\\python311\\3.11.9\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of 'a': tensor([4., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# a) Initialization and Data Types\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)  # From list\n",
    "y = torch.ones((2, 3))                            # Matrix of ones\n",
    "z = torch.randn((2, 3))                           # Random normal distribution\n",
    "\n",
    "# b) Arithmetic, Indexing, and Reshaping\n",
    "sum_res = x + 10                                  # Scalar addition (Broadcasting)\n",
    "reshaped = z.view(1, 6)                           # Reshape 2x3 to 1x6\n",
    "first_row = z[0, :]                               # Indexing\n",
    "\n",
    "# c) Automatic Differentiation (Autograd)\n",
    "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "b = a**2 + 5\n",
    "out = b.sum()\n",
    "out.backward()                                    # Computes gradients\n",
    "print(f\"Gradients of 'a': {a.grad}\")              # Should be 2*a -> [4.0, 6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31460745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication Result:\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "# Defining matrices for linear algebra\n",
    "mat_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "mat_b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "# Operations\n",
    "matmul = torch.matmul(mat_a, mat_b)                # Matrix Multiplication\n",
    "transpose = mat_a.T                                # Transpose\n",
    "inverse = torch.linalg.inv(mat_a)                  # Inverse of a matrix\n",
    "determinant = torch.linalg.det(mat_a)              # Determinant\n",
    "\n",
    "print(f\"Matrix Multiplication Result:\\n{matmul}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98c1f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND(1,1): 1\n",
      "OR(1,0): 1\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def solve_gate(inputs, weights, bias):\n",
    "    # Convert inputs to tensor\n",
    "    x = torch.tensor(inputs, dtype=torch.float32)\n",
    "    w = torch.tensor(weights, dtype=torch.float32)\n",
    "    b = torch.tensor(bias, dtype=torch.float32)\n",
    "    \n",
    "    # Perceptron math: (x * w) + b\n",
    "    z = torch.dot(x, w) + b\n",
    "    return 1 if z >= 0 else 0\n",
    "\n",
    "# AND Gate: Weights [1, 1], Bias -1.5\n",
    "print(f\"AND(1,1): {solve_gate([1, 1], [1, 1], -1.5)}\") \n",
    "\n",
    "# OR Gate: Weights [1, 1], Bias -0.5\n",
    "print(f\"OR(1,0): {solve_gate([1, 0], [1, 1], -0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR Data\n",
    "X_xor = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float32)\n",
    "Y_xor = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "# Neural Network Architecture\n",
    "xor_model = nn.Sequential(\n",
    "    nn.Linear(2, 4),   # Hidden Layer (2 inputs -> 4 neurons)\n",
    "    nn.ReLU(),         # Activation\n",
    "    nn.Linear(4, 1),   # Output Layer (4 neurons -> 1 output)\n",
    "    nn.Sigmoid()       # Final squeeze to 0 or 1\n",
    ")\n",
    "\n",
    "# Training logic\n",
    "optimizer = torch.optim.SGD(xor_model.parameters(), lr=0.1)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = xor_model(X_xor)\n",
    "    loss = loss_fn(prediction, Y_xor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"XOR Results after training:\", (xor_model(X_xor) > 0.5).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669043f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1st Layer: 2 inputs to 2 hidden neurons [cite: 14, 20]\n",
    "        self.layer1 = nn.Linear(2, 2) \n",
    "        # 2nd Layer: 2 hidden neurons to 1 output (h^2) [cite: 23]\n",
    "        self.layer2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # f(z) represents the activation function in the diagram\n",
    "        x = torch.sigmoid(self.layer1(x)) \n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Testing the model with sample inputs x1, x2 [cite: 20]\n",
    "reg_model = LabRegressionModel()\n",
    "sample_input = torch.tensor([0.5, 0.8]) \n",
    "prediction = reg_model(sample_input)\n",
    "print(f\"Regression prediction (h^2): {prediction.item()}\")\n",
    "print(f\"Model Parameters: {[param.data for param in reg_model.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e98a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
